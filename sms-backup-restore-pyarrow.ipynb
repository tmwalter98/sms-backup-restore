{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from minio import Minio\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "from mypy_boto3_s3.client import S3Client\n",
    "from mypy_boto3_s3.paginator import ListObjectsV2Paginator\n",
    "from mypy_boto3_s3.service_resource import S3ServiceResource\n",
    "from mypy_boto3_s3.service_resource import ServiceResourceBucketsCollection\n",
    "from mypy_boto3_s3.service_resource import Bucket\n",
    "from mypy_boto3_s3.service_resource import (\n",
    "    BucketObjectsCollection,\n",
    "    Object,\n",
    "    ObjectSummary,\n",
    ")\n",
    "from hashlib import sha256\n",
    "import tqdm\n",
    "import base64\n",
    "from lxml import etree\n",
    "import re\n",
    "from lxml.etree import Element\n",
    "from smart_open import s3 as smart_open_s3\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from src.schemas import MMS, SMS, Call, CorrespondenceBase\n",
    "\n",
    "from src.utils import replace_null_with_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"sms-backup-restore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credentials.json\", \"r\") as fp:\n",
    "    creds = json.load(fp)\n",
    "    access_key = creds[\"accessKey\"]\n",
    "    secret_key = creds[\"secretKey\"]\n",
    "\n",
    "boto3_session = boto3.Session(\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key,\n",
    ")\n",
    "s3_client = boto3_session.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://192.168.103.69:9000\",\n",
    "    verify=False,\n",
    ")\n",
    "s3_resource: S3ServiceResource = boto3_session.resource(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://192.168.103.69:9000\",\n",
    "    verify=False,\n",
    ")\n",
    "\n",
    "dynamodb = boto3.resource(\n",
    "    \"dynamodb\",\n",
    "    endpoint_url=\"http://192.168.103.69:8000\",\n",
    "    verify=False,\n",
    ")\n",
    "\n",
    "\n",
    "if BUCKET_NAME not in [b[\"Name\"] for b in s3_client.list_buckets().get(\"Buckets\")]:\n",
    "    s3_client.create_bucket(Bucket=BUCKET_NAME)\n",
    "bucket: Bucket = s3_resource.Bucket(BUCKET_NAME)\n",
    "\n",
    "bucket_objs: BucketObjectsCollection = list(bucket.objects.all())\n",
    "backups = [\n",
    "    obj for obj in bucket.objects.all() if re.search(r\"^[\\w\\d_-]+\\.xml\", obj.key)\n",
    "]\n",
    "backups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tag(elem: Element) -> CorrespondenceBase:\n",
    "    e_data = replace_null_with_none(dict(elem.attrib))\n",
    "\n",
    "    match elem.tag:\n",
    "        case \"call\":\n",
    "            return Call.model_validate(e_data)\n",
    "        case \"sms\":\n",
    "            return SMS.model_validate(e_data)\n",
    "        case \"mms\":\n",
    "            parts = [\n",
    "                replace_null_with_none(dict(part.attrib))\n",
    "                for part in elem.findall(\".//part\")\n",
    "            ]\n",
    "            parts1 = []\n",
    "            for part in parts:\n",
    "                if part[\"ct\"] not in [\"application/smil\", \"text/plain\"] and bool(\n",
    "                    part[\"data\"]\n",
    "                ):\n",
    "                    data = base64.b64decode(part[\"data\"])\n",
    "                    data_sha256 = sha256(data).hexdigest()\n",
    "                    key = f\"parts/{data_sha256}\"\n",
    "                    try:\n",
    "                        s3_client.head_object(Bucket=BUCKET_NAME, Key=key)\n",
    "                    except Exception:\n",
    "                        bucket.put_object(Body=data, Key=key, ContentType=part[\"ct\"])\n",
    "\n",
    "                    part[\"data\"] = data_sha256\n",
    "                    assert part[\"data\"] == data_sha256\n",
    "                parts1.append(part)\n",
    "\n",
    "            addrs = [\n",
    "                replace_null_with_none(dict(addr.attrib))\n",
    "                for addr in elem.findall(\".//addr\")\n",
    "            ]\n",
    "            e_data.update({\"parts\": parts1, \"addrs\": addrs})\n",
    "\n",
    "            return MMS.model_validate(e_data)\n",
    "        case _:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_backup(\n",
    "    s3_client: S3Client, bucket_name: str, backup_key: str\n",
    ") -> List[Dict[str, Any]]:\n",
    "    fin: smart_open_s3.Reader = smart_open_s3.open(\n",
    "        bucket_name,\n",
    "        backup_key,\n",
    "        mode=\"rb\",\n",
    "        defer_seek=True,\n",
    "        client=s3_client,\n",
    "    )\n",
    "    seekable_reader = fin._raw_reader\n",
    "\n",
    "    # Creates document parser with the buffered file\n",
    "    context = etree.iterparse(seekable_reader, recover=True, encoding=\"utf-8\")\n",
    "\n",
    "    # Skips to the children of interest\n",
    "    context = iter(context)\n",
    "    next(context)\n",
    "\n",
    "    tag_data = {}\n",
    "    for event, elem in context:\n",
    "        tag_parsed = process_tag(elem=elem)\n",
    "        if isinstance(tag_parsed, CorrespondenceBase):\n",
    "            id = np.array(tag_parsed.__hash__()).astype(np.uint32).item()\n",
    "            elem_processed = {\"id\": id, **tag_parsed.model_dump()}\n",
    "\n",
    "            tags = tag_data.get(elem.tag, [])\n",
    "            tags.append(elem_processed)\n",
    "            tag_data.update({elem.tag: tags})\n",
    "\n",
    "    fin.close()\n",
    "    return tag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from redis.commands.json.path import Path\n",
    "\n",
    "\n",
    "r = redis.Redis(host=\"localhost\", port=6379)\n",
    "\n",
    "with tqdm.tqdm(backups) as t:\n",
    "    for backup in t:\n",
    "        t.set_description(f\"processing {backup.key}\")\n",
    "        processed_backup = process_backup(\n",
    "            s3_client=s3_client, bucket_name=bucket.name, backup_key=backup.key\n",
    "        )\n",
    "\n",
    "        parts_count = 0\n",
    "        pipe = r.pipeline()\n",
    "        for element_type, elements in processed_backup.items():\n",
    "            for e in elements:\n",
    "                e_key = f'{element_type}:{e[\"id\"]}'\n",
    "                pipe.json().set(e_key, Path.root_path(), e)\n",
    "        pipe.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = r.pipeline()\n",
    "[pipe.json().get(k) for k in r.keys(\"mms:*\")]\n",
    "mms = pipe.execute()\n",
    "df = pd.DataFrame(mms)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_schema = pa.schema(\n",
    "    [\n",
    "        pa.field(\"date\", pa.timestamp(unit=\"ms\", tz=\"EDT\")),\n",
    "        pa.field(\"readable_date\", pa.string()),\n",
    "        pa.field(\"contact_name\", pa.string()),\n",
    "    ]\n",
    ")\n",
    "calls_schema = pa.unify_schemas(\n",
    "    [\n",
    "        common_schema,\n",
    "        pa.schema(\n",
    "            [\n",
    "                pa.field(\"number\", pa.string()),\n",
    "                pa.field(\"duration\", pa.uint32()),\n",
    "                pa.field(\"type\", pa.uint8()),\n",
    "                pa.field(\"presentation\", pa.uint8()),\n",
    "                pa.field(\"subscription_id\", pa.string()),\n",
    "                pa.field(\"post_dial_digits\", pa.string()),\n",
    "                pa.field(\"subscription_component_name\", pa.string()),\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=tag_data.get(\"call\"), columns=[field.name for field in calls_schema]\n",
    ")\n",
    "df[\"date\"] = df[\"date\"].apply(lambda x: pd.Timestamp(int(x), unit=\"ms\"))\n",
    "df = df.astype({field.name: pd.ArrowDtype(field.type) for field in calls_schema})\n",
    "\n",
    "# Set dtypes for each column based on the schema\n",
    "table = pa.Table.from_pandas(df, schema=calls_schema)\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_schema_unique = pa.schema(\n",
    "    [\n",
    "        pa.field(\"protocol\", pa.string()),\n",
    "        pa.field(\"address\", pa.string()),\n",
    "        pa.field(\"type\", pa.string()),\n",
    "        pa.field(\"subject\", pa.null()),\n",
    "        pa.field(\"body\", pa.string()),\n",
    "        pa.field(\"toa\", pa.null()),\n",
    "        pa.field(\"sc_toa\", pa.null()),\n",
    "        pa.field(\"service_center\", pa.string()),\n",
    "        pa.field(\"read\", pa.string()),\n",
    "        pa.field(\"status\", pa.string()),\n",
    "        pa.field(\"locked\", pa.string()),\n",
    "        pa.field(\"date_sent\", pa.timestamp(unit=\"ms\", tz=\"EDT\")),\n",
    "        pa.field(\"sub_id\", pa.string()),\n",
    "        pa.field(\"contact_name\", pa.string()),\n",
    "    ]\n",
    ")\n",
    "sms_schema = pa.unify_schemas([common_schema, sms_schema_unique])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=tag_data.get(\"sms\"))\n",
    "df[\"date\"] = df[\"date\"].apply(lambda x: pd.Timestamp(int(x), unit=\"ms\"))\n",
    "df[\"date_sent\"] = df[\"date_sent\"].apply(lambda x: pd.Timestamp(int(x), unit=\"ms\"))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_df = pd.DataFrame(data=tag_data.get(\"mms\"))\n",
    "mms_df[\"date\"] = mms_df[\"date\"].apply(lambda x: pd.Timestamp(int(x), unit=\"ms\"))\n",
    "mms_df[\"date_sent\"] = mms_df[\"date_sent\"].apply(\n",
    "    lambda x: pd.Timestamp(int(x), unit=\"ms\")\n",
    ")\n",
    "mms_df[\"seen\"] = mms_df[\"seen\"].apply(lambda x: bool(x))\n",
    "mms_df[\"msg_box\"] = mms_df[\"msg_box\"].astype(int)\n",
    "mms_schema_unique = pa.schema(\n",
    "    [\n",
    "        pa.field(\"rr\", pa.string()),\n",
    "        pa.field(\"sub\", pa.string()),\n",
    "        pa.field(\"ct_t\", pa.string()),\n",
    "        pa.field(\"read_status\", pa.null()),\n",
    "        pa.field(\"seen\", pa.bool_()),\n",
    "        pa.field(\"msg_box\", pa.uint8()),\n",
    "        pa.field(\"address\", pa.string()),\n",
    "        pa.field(\"sub_cs\", pa.string()),\n",
    "        pa.field(\"resp_st\", pa.string()),\n",
    "        pa.field(\"retr_st\", pa.null()),\n",
    "        pa.field(\"d_tm\", pa.null()),\n",
    "        pa.field(\"text_only\", pa.string()),\n",
    "        pa.field(\"exp\", pa.string()),\n",
    "        pa.field(\"locked\", pa.string()),\n",
    "        pa.field(\"m_id\", pa.string()),\n",
    "        pa.field(\"st\", pa.null()),\n",
    "        pa.field(\"retr_txt_cs\", pa.null()),\n",
    "        pa.field(\"retr_txt\", pa.null()),\n",
    "        pa.field(\"creator\", pa.string()),\n",
    "        pa.field(\"date_sent\", pa.timestamp(unit=\"ms\", tz=\"EDT\")),\n",
    "        pa.field(\"read\", pa.string()),\n",
    "        pa.field(\"m_size\", pa.string()),\n",
    "        pa.field(\"rpt_a\", pa.null()),\n",
    "        pa.field(\"ct_cls\", pa.null()),\n",
    "        pa.field(\"pri\", pa.string()),\n",
    "        pa.field(\"sub_id\", pa.string()),\n",
    "        pa.field(\"tr_id\", pa.string()),\n",
    "        pa.field(\"resp_txt\", pa.null()),\n",
    "        pa.field(\"ct_l\", pa.string()),\n",
    "        pa.field(\"m_cls\", pa.string()),\n",
    "        pa.field(\"d_rpt\", pa.string()),\n",
    "        pa.field(\"v\", pa.string()),\n",
    "        pa.field(\"m_type\", pa.string()),\n",
    "        pa.field(\n",
    "            \"parts\",\n",
    "            pa.list_(\n",
    "                pa.struct(\n",
    "                    [\n",
    "                        pa.field(\"cd\", pa.string()),\n",
    "                        pa.field(\"chset\", pa.string()),\n",
    "                        pa.field(\"cid\", pa.string()),\n",
    "                        pa.field(\"cl\", pa.string()),\n",
    "                        pa.field(\"ct\", pa.string()),\n",
    "                        pa.field(\"ctt_s\", pa.string()),\n",
    "                        pa.field(\"ctt_t\", pa.string()),\n",
    "                        pa.field(\"fn\", pa.string()),\n",
    "                        pa.field(\"seq\", pa.string()),\n",
    "                        pa.field(\"text\", pa.string()),\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "        pa.field(\n",
    "            \"addrs\",\n",
    "            pa.list_(\n",
    "                pa.struct(\n",
    "                    [\n",
    "                        pa.field(\"address\", pa.string()),\n",
    "                        pa.field(\"type\", pa.string()),\n",
    "                        pa.field(\"charset\", pa.string()),\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "mms_schema = pa.unify_schemas([common_schema, mms_schema_unique])\n",
    "\n",
    "table = pa.Table.from_pandas(mms_df, schema=mms_schema)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(mms_df[\"parts\"])\n",
    "for field in table.schema:\n",
    "    print(f'pa.field(\"{field.name}\", pa.{field.type}()),')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def upload_file_s3(bucket: Bucket, file_path: str):\n",
    "    key = os.path.basename(file_path)\n",
    "    with open(file_path, \"rb\") as fp:\n",
    "        bucket.upload_fileobj(fp, Key=key, ExtraArgs={\"ContentType\": \"application/xml\"})\n",
    "\n",
    "\n",
    "for file in tqdm.tqdm(glob.glob(\"./backups/*.xml\")):\n",
    "    upload_file_s3(bucket, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = dynamodb.create_table(\n",
    "    TableName=\"sms-backup-restore\",\n",
    "    KeySchema=[\n",
    "        {\"AttributeName\": \"id\", \"KeyType\": \"HASH\"},  # Partition_key\n",
    "        {\"AttributeName\": \"timestamp\", \"KeyType\": \"RANGE\"},  # Sort_key\n",
    "    ],\n",
    "    AttributeDefinitions=[\n",
    "        {\"AttributeName\": \"id\", \"AttributeType\": \"N\"},\n",
    "        {\"AttributeName\": \"timestamp\", \"AttributeType\": \"S\"},\n",
    "    ],\n",
    "    ProvisionedThroughput={\"ReadCapacityUnits\": 10, \"WriteCapacityUnits\": 10},\n",
    ")\n",
    "for element_type, elements in processed_backup.items():\n",
    "    for e in elements:\n",
    "        table.put_item(Item=e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializer = boto3.dynamodb.types.TypeSerializer()\n",
    "serialize_dynamodb = lambda x: {k: serializer.serialize(v) for k, v in x.items()}\n",
    "from itertools import batched\n",
    "\n",
    "for batch in tqdm.tqdm(batched(processed_backup, 25)):\n",
    "    put_requests = [{ 'PutRequest': { 'Item': serialize_dynamodb(e) }} for e in batch]\n",
    "    response = dynamodb.batch_write_item(RequestItems={'sms-backup-restore': put_requests})\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Table status:\", table.table_status)\n",
    "deserializer = boto3.dynamodb.types.TypeDeserializer()\n",
    "#python_data = {k: deserializer.deserialize(v) for k, v in low_level_data.items()}\n",
    "\n",
    "# To go from python to low-level format\n",
    "print(len(json.dumps(put_requests)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sms-backup-restore-64-JIJYD-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
